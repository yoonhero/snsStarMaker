{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"./intents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'greeting',\n",
       " 'patterns': ['안녕?', '반가워.', '반가웡', '헤이', '왓썹', '방가방가', '안뇽'],\n",
       " 'responses': ['안녕ㅋㅋ', '하이!', '헬로우', 'ㅋㅋㅋ', '머해 머해', '나도 반갑다 펭귄'],\n",
       " 'context_set': ''}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "labels = []\n",
    "docs_x = []\n",
    "docs_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data.intents:\n",
    "    tag = row.get(\"tag\")\n",
    "    for pattern in row.get(\"patterns\"):\n",
    "        wrds = okt.morphs(pattern)\n",
    "        t_wrds = [w for w in wrds if w not in words]\n",
    "        words.extend(t_wrds)\n",
    "        \n",
    "        docs_x.append(wrds)\n",
    "        docs_y.append(tag)\n",
    "\n",
    "    if tag not in labels:\n",
    "        labels.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕',\n",
       " '?',\n",
       " '반가워',\n",
       " '.',\n",
       " '반가웡',\n",
       " '헤이',\n",
       " '왓썹',\n",
       " '방가',\n",
       " '방가',\n",
       " '안뇽',\n",
       " '넌',\n",
       " '누구',\n",
       " '야',\n",
       " '니',\n",
       " '너',\n",
       " '가',\n",
       " '인지',\n",
       " '궁금해',\n",
       " '이름',\n",
       " '이',\n",
       " '뭐',\n",
       " '어디서',\n",
       " '왔어',\n",
       " '왔니',\n",
       " '너무',\n",
       " '귀여워',\n",
       " '!',\n",
       " '매력',\n",
       " '만점',\n",
       " '이야',\n",
       " '이제',\n",
       " '그만',\n",
       " 'ㅎㅎ',\n",
       " '즐거',\n",
       " '웟',\n",
       " '어',\n",
       " '잘가']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = len(words)\n",
    "\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 0, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "result = le.fit_transform(docs_y)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, patterns, labels):\n",
    "        self.patterns = patterns\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patterns)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return torch.tensor(self.patterns[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding = torch.zeros(max_length)\n",
    "\n",
    "one_hot_encoding[1] = 1\n",
    "\n",
    "one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['어디서', '!', '넌', '그만', '너', '안녕', '이제', '너무', '방가', '반가웡', '웟', '이야', '왔니', '왔어', 'ㅎㅎ', '야', '인지', '가', '반가워', '귀여워', '뭐', '이름', '즐거', '?', '매력', '어', '안뇽', '왓썹', '헤이', '니', '.', '누구', '방가', '잘가', '만점', '이', '궁금해']\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(words)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = []\n",
    "\n",
    "for x in docs_x:\n",
    "    one_hot_encoding = torch.zeros(max_length)\n",
    "\n",
    "    for word in x:\n",
    "        if word in words:\n",
    "            t_index = words.index(word)\n",
    "            one_hot_encoding[t_index] = 1\n",
    "\n",
    "    training_x.append(one_hot_encoding.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_y = []\n",
    "\n",
    "for label in docs_y:\n",
    "    one_hot_encoding = np.zeros(len(labels))\n",
    "    \n",
    "    t_index = labels.index(label)\n",
    "\n",
    "    one_hot_encoding[t_index] = 1\n",
    "\n",
    "    training_y.append(t_index)\n",
    "\n",
    "training_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, label_size):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, label_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(max_length, len(labels))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/100] / Loss: 1.6009521484375\n",
      "Epoch: [1/100] / Loss: 1.3709951639175415\n",
      "Epoch: [2/100] / Loss: 0.9497727751731873\n",
      "Epoch: [3/100] / Loss: 0.5204460024833679\n",
      "Epoch: [4/100] / Loss: 0.2673269510269165\n",
      "Epoch: [5/100] / Loss: 0.12054628878831863\n",
      "Epoch: [6/100] / Loss: 0.07913297414779663\n",
      "Epoch: [7/100] / Loss: 0.022363364696502686\n",
      "Epoch: [8/100] / Loss: 0.007029101252555847\n",
      "Epoch: [9/100] / Loss: 0.0023170432541519403\n",
      "Epoch: [10/100] / Loss: 0.0009882923914119601\n",
      "Epoch: [11/100] / Loss: 0.0006389086483977735\n",
      "Epoch: [12/100] / Loss: 0.00042128676432184875\n",
      "Epoch: [13/100] / Loss: 0.0003173970908392221\n",
      "Epoch: [14/100] / Loss: 0.0002564969763625413\n",
      "Epoch: [15/100] / Loss: 0.00019871963013429195\n",
      "Epoch: [16/100] / Loss: 0.00016030836559366435\n",
      "Epoch: [17/100] / Loss: 0.0001238281693076715\n",
      "Epoch: [18/100] / Loss: 0.00010843225754797459\n",
      "Epoch: [19/100] / Loss: 9.222234803019091e-05\n",
      "Epoch: [20/100] / Loss: 8.613857789896429e-05\n",
      "Epoch: [21/100] / Loss: 7.609821477672085e-05\n",
      "Epoch: [22/100] / Loss: 6.890620716148987e-05\n",
      "Epoch: [23/100] / Loss: 6.790345651097596e-05\n",
      "Epoch: [24/100] / Loss: 5.6486136600142345e-05\n",
      "Epoch: [25/100] / Loss: 5.476224760059267e-05\n",
      "Epoch: [26/100] / Loss: 4.582188921631314e-05\n",
      "Epoch: [27/100] / Loss: 3.855602699331939e-05\n",
      "Epoch: [28/100] / Loss: 3.387613469385542e-05\n",
      "Epoch: [29/100] / Loss: 3.1977437174646184e-05\n",
      "Epoch: [30/100] / Loss: 2.6757654268294573e-05\n",
      "Epoch: [31/100] / Loss: 2.6279200028511696e-05\n",
      "Epoch: [32/100] / Loss: 2.1454978195833974e-05\n",
      "Epoch: [33/100] / Loss: 1.864716614363715e-05\n",
      "Epoch: [34/100] / Loss: 1.8557793737272732e-05\n",
      "Epoch: [35/100] / Loss: 1.6428753951913677e-05\n",
      "Epoch: [36/100] / Loss: 1.4615880900237244e-05\n",
      "Epoch: [37/100] / Loss: 1.6001651601982303e-05\n",
      "Epoch: [38/100] / Loss: 1.362588500342099e-05\n",
      "Epoch: [39/100] / Loss: 1.2849409358750563e-05\n",
      "Epoch: [40/100] / Loss: 1.3165627933631185e-05\n",
      "Epoch: [41/100] / Loss: 1.1445456948422361e-05\n",
      "Epoch: [42/100] / Loss: 1.0816328540386166e-05\n",
      "Epoch: [43/100] / Loss: 1.0149112313229125e-05\n",
      "Epoch: [44/100] / Loss: 9.758389751368668e-06\n",
      "Epoch: [45/100] / Loss: 9.432239494344685e-06\n",
      "Epoch: [46/100] / Loss: 9.526619578537066e-06\n",
      "Epoch: [47/100] / Loss: 8.980262464319821e-06\n",
      "Epoch: [48/100] / Loss: 8.83457232703222e-06\n",
      "Epoch: [49/100] / Loss: 8.243509000749327e-06\n",
      "Epoch: [50/100] / Loss: 7.938874659885187e-06\n",
      "Epoch: [51/100] / Loss: 7.56138751967228e-06\n",
      "Epoch: [52/100] / Loss: 7.463706879207166e-06\n",
      "Epoch: [53/100] / Loss: 7.137546617741464e-06\n",
      "Epoch: [54/100] / Loss: 6.953772754059173e-06\n",
      "Epoch: [55/100] / Loss: 6.957088771741837e-06\n",
      "Epoch: [56/100] / Loss: 6.478603154391749e-06\n",
      "Epoch: [57/100] / Loss: 6.420657882699743e-06\n",
      "Epoch: [58/100] / Loss: 6.236882200028049e-06\n",
      "Epoch: [59/100] / Loss: 6.162381851027021e-06\n",
      "Epoch: [60/100] / Loss: 5.862706984771648e-06\n",
      "Epoch: [61/100] / Loss: 5.771648375230143e-06\n",
      "Epoch: [62/100] / Loss: 5.6954886531457305e-06\n",
      "Epoch: [63/100] / Loss: 5.710392997571034e-06\n",
      "Epoch: [64/100] / Loss: 6.013375241309404e-06\n",
      "Epoch: [65/100] / Loss: 5.188860541238682e-06\n",
      "Epoch: [66/100] / Loss: 4.998460099159274e-06\n",
      "Epoch: [67/100] / Loss: 5.1077363423246425e-06\n",
      "Epoch: [68/100] / Loss: 4.879255357082002e-06\n",
      "Epoch: [69/100] / Loss: 4.9189934543392155e-06\n",
      "Epoch: [70/100] / Loss: 4.546468062471831e-06\n",
      "Epoch: [71/100] / Loss: 4.978594461135799e-06\n",
      "Epoch: [72/100] / Loss: 4.601108230417594e-06\n",
      "Epoch: [73/100] / Loss: 4.430574790603714e-06\n",
      "Epoch: [74/100] / Loss: 4.2931546886393335e-06\n",
      "Epoch: [75/100] / Loss: 4.392495611682534e-06\n",
      "Epoch: [76/100] / Loss: 4.4703097046294715e-06\n",
      "Epoch: [77/100] / Loss: 4.03487274525105e-06\n",
      "Epoch: [78/100] / Loss: 4.231895218254067e-06\n",
      "Epoch: [79/100] / Loss: 4.127588454139186e-06\n",
      "Epoch: [80/100] / Loss: 3.682216629385948e-06\n",
      "Epoch: [81/100] / Loss: 3.5762534480454633e-06\n",
      "Epoch: [82/100] / Loss: 3.6424817153601907e-06\n",
      "Epoch: [83/100] / Loss: 3.5398297768551856e-06\n",
      "Epoch: [84/100] / Loss: 3.6375147374201333e-06\n",
      "Epoch: [85/100] / Loss: 3.516651531754178e-06\n",
      "Epoch: [86/100] / Loss: 3.41731197295303e-06\n",
      "Epoch: [87/100] / Loss: 3.3593632906558923e-06\n",
      "Epoch: [88/100] / Loss: 3.187173888363759e-06\n",
      "Epoch: [89/100] / Loss: 3.4239335491292877e-06\n",
      "Epoch: [90/100] / Loss: 3.2484342682437273e-06\n",
      "Epoch: [91/100] / Loss: 2.998427817146876e-06\n",
      "Epoch: [92/100] / Loss: 2.995117029058747e-06\n",
      "Epoch: [93/100] / Loss: 2.918955942732282e-06\n",
      "Epoch: [94/100] / Loss: 2.88418709715188e-06\n",
      "Epoch: [95/100] / Loss: 3.177240841978346e-06\n",
      "Epoch: [96/100] / Loss: 2.8129934435128234e-06\n",
      "Epoch: [97/100] / Loss: 2.8394842956913635e-06\n",
      "Epoch: [98/100] / Loss: 2.7053747544414364e-06\n",
      "Epoch: [99/100] / Loss: 2.6341811008023797e-06\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 100\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    avg_loss = 0\n",
    "\n",
    "    for i, (pattern, label) in enumerate(training_dataloader):\n",
    "        pred = model(pattern)\n",
    "\n",
    "        loss = criterion(pred, label)\n",
    "        avg_loss += loss \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss /= len(training_dataloader)\n",
    "    print(f\"Epoch: [{epoch}/{nb_epochs}] / Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(word):\n",
    "    word = okt.morphs(word)\n",
    "\n",
    "    one_hot_encoding = torch.zeros(max_length)\n",
    "\n",
    "    if word in words:\n",
    "        t_index = words.index(word)\n",
    "        one_hot_encoding[t_index] = 1\n",
    "\n",
    "    encoded_label = torch.argmax(model(one_hot_encoding))\n",
    "\n",
    "    tag = labels[encoded_label]\n",
    "\n",
    "    responses = list(filter(lambda x: x[\"tag\"] == tag, data.intents.tolist()))\n",
    "    response = random.choice(responses[0][\"responses\"])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헬로우\n"
     ]
    }
   ],
   "source": [
    "print(inference(\"아 엔터키 ㅡ게 만드는거ㅋㅋㅋㅋㅋㅋㅋ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9585e0e58f3ada4c387d89b399b9d9bb88b52954ed4e2235f58d5a052e970ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
